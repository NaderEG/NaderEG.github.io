<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Nader EG Blog | CVM Algorithm</title>
    <link rel="stylesheet" href="blog-style.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/charter-webfont@4/charter.min.css" />
    <style>
        .codeblock {
            align-items: left;
            background-color: #f4f4f4;
            border: 1px solid #ddd;
            padding: 10px;
            font-family: monospace;
            font-size: 17px;
            white-space: pre-wrap;       /* Since CSS 2.1 */
            white-space: -moz-pre-wrap;  /* Mozilla, since 1999 */
            white-space: -pre-wrap;      /* Opera 4-6 */
            white-space: -o-pre-wrap;    /* Opera 7 */
            word-wrap: break-word;       /* Internet Explorer 5.5+ */
            
        }
    </style>
</head>
<body>
    <main>
        <article>
            <h1 class="title">The CVM Algorithm</h1>
            <h2 class="subtitle">An Algorithm for Estimating the Number of Unique Elements in a Data Stream</h2>
            <p class="publisher-tag">Published on <time datetime="2024-02-17">February 17, 2024</time> by <a href="../index.html" class="link">Nader El-Ghotmi</a></p>
            <section class="post-content">
                <h2 class="section-title">Introduction</h2>
                <p>The problem of counting the number of distinct elements in a data stream, 
                    often referred to as the Count Distinct Problem, is a widely studied problem
                     in the field of computer science. The Count Distinct Problem has applications
                      in various fields. For example, say that you own a website and you want to 
                      count the number of unique visitors (IP addresses) that are visiting your 
                      site in the past month. This is one use case of the algorithm but there 
                      are also applications in biology, networking, and more.</p>

                <p>This problem can be solved trivially if we assume we have an effectively infinite 
                    amount of space. We would simply store the values into a data structure, such 
                    as a Hashmap, that can efficiently search and add values. Unfortunately, these 
                    data streams are rarely so small as to afford us the convenience of using a 
                    proportionally large data structure. As such, there is motivation to design 
                    an algorithm for this problem that does not have space that scales with the 
                    number of distinct elements in the stream. This restriction has led computer 
                    scientists to designing algorithms which can approximate the number of distinct elements 
                    while using a fraction of the space. </p>

                    <p> 
                        The HyperLogLog Algorithm is a popular solution to this problem. 
                        However, recently Sourav Chakraborty, N. V. Vinodchandran, and Kuldeep S. Meel 
                        proposed another algorithm. This algorithm was then refined by Donald Knuth, 
                        who also named it "The CVM Algorithm" (referring to the first letter of the last 
                        names of each of the original creators) in the same paper. Unlike the HyperLogLog algorithm, 
                        which uses hashing, the CVM algorithm makes use of clever statistic in order to provide its estimation. 
                        This means it is not only simple to understand, it's also simple to analyze.
                    </p>

                    <p>
                        In this post I'll be going over the algorithm, how to implement it, it's runtime,
                        the proof of its correctness, and then I'll also provide a statistical analysis of its accuracy.

                    </p>

                    <h2 class="section-title">Treaps</h2>
                    <p>Both the implementation and the runtime analysis of the CVM algorithm will make use of a 
                        lesser known data structure known as a Treap. If the reader is not familiar with Treaps they
                         are recommended to read this section. If you are already familiar with Treaps feel free to skip ahead. 
                        
                    </p>
                    <p>
                       A Treap, as the name suggests, is a combination of a Binary Search Tree and a Max-Heap. Each node has a
                       key and a value. The tree is sorted like a Max Heap in
                       terms of the value, meaning the value of a node is always
                       greater than the value of its children, and it is sorted as a
                       Binary Search Tree in terms of the key, meaning the key
                       of the left child will always be equal or less then the key
                       of the parent, and the key of the right child will always
                       be greater than the key of the parent. This allows for
                       finding the max value to be an \(O(1)\) operation. Searching, inserting, and deleting are all expected to be \(O(log n)\)
                       when the values are randomly generated (as they are in this implementation). Otherwise, it is possible to construct an
                       imbalanced Treap which will have search, insertion, and deletion times of \(O(n)\), but this is not a concern for us.
                    </p>

                    <h2 class="section-title">The Algorithm</h2>
                    <pre class="codeblock">
                        <code>
        Algorithm CVM
            Input: Data stream A = [a<span style="vertical-align: sub;">1</span>, a<span style="vertical-align: sub;">2</span>, ..., a<span style="vertical-align: sub;">n</span>] of size n,
            buffer size s
            Output: Estimation of the number of distinct elements in A

            t ← 0
            p ← 1
            B ← Empty Treap
            while t &lt n do
                t ← t + 1
                a ← a<span style="vertical-align: sub;">t</span>
                if a is in B then
                    delete a from B
                end if
                u ← random number in [0, 1)
                if u &ge; p then
                    NEXT
                else if |B| &lt s then
                    insert (a, u) into B
                    NEXT
                else
                    (a', u') ← (a, u) of max u in B
                    if u > u' then
                        p ← u
                    else
                        Delete (a', u') from B
                        Insert (a, u) into B
                        p ← u'
                    end if
                end if
            end while
            Return |B|/p
        end function
                        </code>
                        </pre>
                        <p>
                            The runtime of the algorithm is \(O(nlogs)\) since it iterates over every element in the data stream and during each iteration there 
                            is a chance that the algorithm will add, delete, or search in the buffer (which is a Treap of size \(s\)). This runtime is pretty good, since
                            we were expecting at least a runtime of \(O(n)\) since you'd expect the algorithm to iterate over every element in the stream (if the stream 
                            was live rather than static you'd be doing the analysis as you receive the data anyways). Then we simply have an increase by a factor of \(log(s)\), 
                            and \(s\) will be small compared to \(n\), as we'll see.

                        </p>
                        <p>
                            While the algorithm looks easy to implement it may not be immediately apparent why 
                            it provides an estimation of the number of distinct elements in the stream. The general 
                            idea is that the algorithm maintains the property \(Pr(a_j \in B_t) = p_t, \; \forall j \in \;[1, t]\).
                            If you have a keen eye, you might see what the trick is, but no worries if you haven't caught it, first let us check whether the algorithm 
                            successfully maintains this property or not. Within the algorithm, at a timestep \(t\) an element is only added to \(B\) when the random uniform 
                            deviate \(u\) associated with the element is less than \(p_t\). This implies that the probability of an element being in \(B\) is \(p_t\) However, we do update the 
                            value of \(p\) throughout the algorithm meaning we must make sure that every element in \(B\) at that point has a \(u\) value lesser than \(p\). If \(u > u'\) then 
                            we set \(p = u\), the property is upheld in this case because \(u'\) is the largest value of \(u_j\in B\). If \(u \leq u'\) then we delete \(u'\) which is greater than \(u\), 
                            and insert \(u\) into \(B\), then we set \(p = u'\) as such, \(p\) must be greater than \(u_j\in B\) in this case since \(u' \geq u\) and \(u'\) was the maximum value of \(u_j\in B\). 
                            This shows that the property is upheld during the execution of the algorithm.
                        </p>
                        <p>
                            Now that we've proven the statement \(Pr(a_j \in B_t) = p_t, \; \forall j \in \;[1, t]\) is true, 
                            let us show how this fact can be used to estimate the cardinality of \(A\). If any element in the 
                            stream \(A_t\) has a probability \(p_t\) of being in \(B_t\) it can be said that the expected 
                            cardinality of \(B_t\) is equal to \(A_t \times p_t\).
                            In other words \(E[|B_t|] = p_t \times |A_t|\). Finally, we can express the same statement as \(\dfrac{E[|B_t|]}{p_t} = |A_t|\).
                            This shows why our return value in the CVM Algorithm gives a valid estimate of the cardinality of \(A\). If you aren't used to working
                            with probabilities this might seem a bit tricky. Just take a moment to really think about it and remember that the equations use random 
                            variables and expected values.
                        </p>

                        <p>
                            Proving that the CVM algorithm is a valid estimation of the Count-Distinct problem is great, but with approximation
                            algorithms we tend to want to know the competetive ratio, in other words, we want to know how wrong the estimation might be.
                            Unfortunately, Donald Knuth was not able to identify the upper bound on error in his paper on the algorithm.
                            Proving this upper bound is beyond my ability as well,
                            however, the lack of a concrete upper bound or competitive ratio motivated me to run simulations of the
                            CVM Algorithm in order to at least observe the margin
                            of error on average cases. This will hopefully provide
                            anyone who wishes to use the algorithm with a rough
                            idea of what a suitable buffer size would be for their
                            data stream.
                        </p>

                        

                    

                        
            </section>
        </article>
    </main>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</body>
</html>
